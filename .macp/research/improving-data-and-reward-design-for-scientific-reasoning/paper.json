{
  "id": "arxiv:2602.08321",
  "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models",
  "authors": [
    "Zijie Chen",
    "Zhenghao Lin",
    "Xiao Liu",
    "Zhenzhong Lan",
    "Yeyun Gong",
    "Peng Cheng"
  ],
  "url": "https://huggingface.co/papers/2602.08321",
  "abstract": "Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr. SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.",
  "discovered_by": "hf_daily_papers",
  "discovered_date": "2026-02-10",
  "status": "discovered",
  "insights": [],
  "_meta": {
    "hf_upvotes": 39,
    "ai_keywords": [
      "large language models",
      "open-ended science questions",
      "data construction",
      "reward design",
      "Dr. SCI dataset",
      "SFT",
      "RL",
      "exploration-expanding SFT",
      "dynamic difficulty curriculum",
      "SciRubric-Guided RL",
      "scientific reasoning",
      "GPQA-diamond",
      "GPQA-general"
    ]
  }
}