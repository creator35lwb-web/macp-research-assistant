{
  "id": "arxiv:2602.08961",
  "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
  "authors": [
    "Ruijie Zhu",
    "Jiahao Lu",
    "Wenbo Hu",
    "Xiaoguang Han",
    "Jianfei Cai",
    "Ying Shan",
    "Chuanxia Zheng"
  ],
  "url": "https://huggingface.co/papers/2602.08961",
  "abstract": "We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system, and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents-despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page",
  "discovered_by": "hf_daily_papers",
  "discovered_date": "2026-02-10",
  "status": "discovered",
  "insights": [],
  "_meta": {
    "hf_upvotes": 3,
    "github_repo": "https://github.com/TencentARC/MotionCrafter",
    "ai_keywords": [
      "video diffusion",
      "4D geometry",
      "dense motion estimation",
      "3D point maps",
      "3D scene flows",
      "shared coordinate system",
      "4D VAE",
      "RGB VAE latents",
      "data normalization",
      "VAE training strategy",
      "diffusion priors"
    ]
  }
}